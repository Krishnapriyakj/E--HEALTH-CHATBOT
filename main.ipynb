{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_model() -> Tuple[RandomForestClassifier, StandardScaler, LabelEncoder]:\n",
    "    # Load dataset from the Excel file\n",
    "    file_path = './content/cancer patient data sets.xlsx'\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "    df['Level'] = label_encoder.fit_transform(df['Level'])\n",
    "\n",
    "    X = df.drop(columns=['Patient Id', 'Level'])  # Drop non-predictive columns\n",
    "    y = df['Level']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return model, scaler, label_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancer_questionaire_tool():\n",
    "    \"\"\"\n",
    "    A Function to evaluate chance of cancer. Use the tool when someone asks to evaluate their chances of being infected by cancer.\n",
    "    Output: The level of Chance Low, Medium, High\n",
    "    \"\"\"\n",
    "    questions = [\n",
    "    \"What is your age?\",\n",
    "    \"What is your gender? (1: Female, 2: Male)\",\n",
    "    \"Rate the air pollution in your area (1 to 10):\",\n",
    "    \"Rate your alcohol consumption (1 to 10):\",\n",
    "    \"Rate the severity of your dust allergy (1 to 10):\",\n",
    "    \"Rate your exposure to occupational hazards (1 to 10):\",\n",
    "    \"Rate your genetic risk of cancer (1 to 10):\",\n",
    "    \"Rate the severity of your chronic lung disease (1 to 10):\",\n",
    "    \"Rate how balanced your diet is (1 to 10):\",\n",
    "    \"Rate your obesity level (1 to 10):\",\n",
    "    \"Rate the level of smoking (1 to 10):\",\n",
    "    \"Rate the passive smoker risk (1 to 10):\",\n",
    "    \"Rate your chest pain severity (1 to 10):\",\n",
    "    \"Rate your coughing blood level (1 to 10):\",\n",
    "    \"Rate your fatigue level (1 to 10):\",\n",
    "    \"Rate your weight loss severity (1 to 10):\",\n",
    "    \"Rate your shortness of breath severity (1 to 10):\",\n",
    "    \"Rate your wheezing level (1 to 10):\",\n",
    "    \"Rate the swallowing difficulty (1 to 10):\",\n",
    "    \"Rate the clubbing of your finger nails (1 to 10):\",\n",
    "    \"Rate the frequency of colds (1 to 10):\",\n",
    "    \"Rate your dry cough level (1 to 10):\",\n",
    "    \"Rate your snoring severity (1 to 10):\"\n",
    "    ]\n",
    "    model, scaler, encoder = get_classification_model()\n",
    "    print(\"\\nPlease answer the following questions:\")\n",
    "    user_input = []\n",
    "    for question in questions:\n",
    "        answer = float(input(question))\n",
    "        user_input.append(answer)\n",
    "\n",
    "    # Preprocess user input\n",
    "    user_input_scaled = scaler.transform([user_input])  # Match user input to dataset features\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(user_input_scaled)\n",
    "    predicted_level = encoder.inverse_transform(prediction)\n",
    "\n",
    "    print(f\"\\nPredicted Cancer Risk Level: {predicted_level[0]}\")\n",
    "    \n",
    "    return predicted_level[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "\n",
      "Please answer the following questions:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Test cell\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcancer_questionaire_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mcancer_questionaire_tool\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m user_input \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[1;32m---> 32\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     user_input\u001b[38;5;241m.\u001b[39mappend(answer)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Preprocess user input\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "#Test cell\n",
    "\n",
    "cancer_questionaire_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import display, Image\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000020BD8539AB0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000020BD855C790>, root_client=<openai.OpenAI object at 0x0000020BD8512770>, root_async_client=<openai.AsyncOpenAI object at 0x0000020BD8539A50>, model_name='llama3.2', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://localhost:11434/v1'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'cancer_questionaire_tool', 'description': 'A Function to evaluate chance of cancer. Use the tool when someone asks to evaluate their chances of being infected by cancer.\\nOutput: The level of Chance Low, Medium, High', 'parameters': {'properties': {}, 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class State(MessagesState):\n",
    "    pass\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"llama3.2\", base_url=\"http://localhost:11434/v1\", api_key=\"llama3.2\")\n",
    "tooler = llm.bind_tools([cancer_questionaire_tool])\n",
    "tooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tooler.invoke([SystemMessage(\"You are a helpful assistant. Answer helpfully and use tool calls when and only when necessary\")])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
